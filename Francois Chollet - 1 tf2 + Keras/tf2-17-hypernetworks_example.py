#!/usr/bin/python3

import tensorflow as tf
print(tf.__version__)

from tensorflow.keras.layers import Layer

class Linear(Layer):
    """y = w.x + b"""

    def __init__(self, units=32):
        super(Linear, self).__init__()
        self.units = units

    def build(self, input_shape):
        self.w = self.add_weight(shape=(input_shape[-1], self.units),
                                 initializer='random_normal',
                                 trainable=True)
        print('self.w',self.w.shape)
        self.b = self.add_weight(shape=(self.units,),
                                 initializer='random_normal',
                                 trainable=True)
        print('self.b', self.b.shape)

    def call(self, inputs):
        return tf.matmul(inputs, self.w) + self.b

# Let's put these concepts into practice with a simple end-to-end example.
#
# A hypernetwork is a deep neural network whose weights are generated by another network (usually smaller).
#
# Let's implement a really trivial hypernetwork: we'll take the Linear layer we defined earlier,
#  and we'll use it to generate the weights of... another Linear layer.


input_dim = 784
classes = 10

# The model we'll actually use (the hypernetwork).
outer_model = Linear(classes)

# It doesn't need to create its own weights, so let's mark it as already built.
# That way, calling `outer_model` won't create new variables.
outer_model.built = True

# The model that generates the weights of the model above.
inner_input_unit = input_dim * classes + classes
print('inner_input_unit',inner_input_unit)
inner_model = Linear(inner_input_unit)

# Loss and optimizer.
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)

# Prepare a dataset.
(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()
dataset = tf.data.Dataset.from_tensor_slices(
    (x_train.reshape(60000, 784).astype('float32') / 255, y_train))

# We'll use a batch size of 1 for this experiment.
dataset = dataset.shuffle(buffer_size=1024).batch(1)

losses = []  # Keep track of the losses over time.
for step, (x, y) in enumerate(dataset):
    with tf.GradientTape() as tape:
        # start with step 0
        # x shape (1, 784)
        print('step', step, 'x',x.shape,'y',y)
        # Predict weights for the outer model.
        weights_pred = inner_model(x)
        print('weights_pred_before', weights_pred.shape)

        # Reshape them to the expected shapes for w and b for the outer model.
        w_pred = tf.reshape(weights_pred[:, :-classes], (input_dim, classes))
        b_pred = tf.reshape(weights_pred[:, -classes:], (classes,))
        print('weights_pred_after', w_pred.shape)
        print('weights_pred_after', b_pred.shape)

        # Set the weight predictions as the weight variables on the outer model.
        outer_model.w = w_pred
        outer_model.b = b_pred

        # Inference on the outer model.
        preds = outer_model(x)
        loss = loss_fn(y, preds)

    # Train only inner model.
    grads = tape.gradient(loss, inner_model.trainable_weights)
    optimizer.apply_gradients(zip(grads, inner_model.trainable_weights))

    # Logging.
    losses.append(float(loss))
    if step % 100 == 0:
        print(step, sum(losses) / len(losses))

    # Stop after 1000 steps.
    if step >= 1000:
        break

    break